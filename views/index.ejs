<!DOCTYPE html>
<html>
<meta charset="utf-8">
  <head>
    <link rel='stylesheet' href='/stylesheets/style.css'/>
  </head>
  <body>
    <div class='nav'>
      <h1><a href="/">CENTAUR</a></h1>
      <ul class='nav-links'>
        <li><a href="/">Home</a></li>
        <li><a href="/ride">Ride</a></li>
      </ul>
    </div>
    <div class='header-image'>
      <h2>Track your riding progress.</h2>
      <p>Centaur is an equine app that tracks <br>your riding sessions.</p>
    </div>
<!--     <div class='spacer'></div>
    <div class='first-about'>
      <div>
        <h2>Every step counts.</h2>
        <p>Feel confident you and your equine partner <br>are on the right track.</p>
        <div class='spacer'></div>
        <img src="/images/iphone.png">
        <div class='points'>
          <ul>
            <li><img src="/images/timer.png">Record your training sessions.</li>
            <li><img src="/images/clipboard.png">Track change over time.</li>
            <li><img src="/images/trophy.png">Reach your goals.</li>
          </ul>
        </div>
      </div>
    </div>
    <div class='spacer'></div> -->
    <div class='about'>
      <h2>About Centaur</h2>
      <p>Centaur is a student project created by myself, Leah Petersen during my time at Ada Developers Academy in Seattle. My initial goal was to create a device to record the movement of my horse, Lola, during training sessions. I initially experimented with a Raspberry Pi and MPU-6500 accelerometer/gyroscope to gather data from Lola moving during her training.</p>
      <figure>
        <img src="/images/pi.jpg">
        <figcaption>First version of hardware, raspberry pi and MPU-6500 accelerometer/gyroscope</figcaption>
      </figure>
      <p>My initial goal was to process the data and find a way to automatically detect what “gait” Lola was in. Horses have three natural gaits, walking (a four beat gait), trotting (a two beat gait) and cantering/galloping (a three beat gait).</p>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/Ev4JmqJ3EYw" frameborder="0" allowfullscreen></iframe>
      <p>The first pass at trying to process the data and recognize these gaits resulted in a custom algorithm, which recognized the patterns in the limited data from one device and one horse. I wanted the next iteration of the project to be a more flexible solution – possibly for any horse and any device.  I wrote a front-end app to gather data from my cell phone and posted it to a server after each session. This hardware solution was less cumbersome and allows anyone with a smart phone to use the app.</p>
      <figure>
        <img src="/images/accel.jpg">
        <figcaption>Acceleration data from the X-axis.</figcaption>
      </figure>
      <p>As for the data processing, machine learning was a possible answer and the first algorithm I tried was <a href="https://en.wikipedia.org/wiki/K-means_clustering">k-means clustering</a>, which sorted the walk, trot and canter ‘clusters’ well but only when the “k” (in this case 3) was manually provided. I wanted an answer that required less manual supervising and finally found the <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">k-nearest neighbors algorithm</a>. This algorithm trains a model with several ‘features’ from the data, in this case I provided features that I felt clearly highlighted the differences between my three gaits.</p>
      <figure>
        <img src="/images/features.jpg">
        <figcaption>Graphs of each feature that is training my model.</figcaption>
      </figure>
      <p>I chose a “supervised” approach to training my model meaning I manually labeled data that I knew was walk, trot or canter.  After training my model and tweaking my algorithm my app can take in unlabeled raw data and predict what sections are walk, trot or canter with good accuracy. Currently my app allows riders to record a riding session, save them in their records and process the data to get total time riding, total time in each gait and see a graph of the overall balance of their acceleration.</p>
      <figure>
        <img src="/images/predict.jpg">
        <figcaption>Example of KNN algorithm model predicting walk (red), trot (green) and canter (blue).</figcaption>
      </figure>
      <p>Moving forward I plan to continue making my machine-learning model more precise and flexible. I want to add more quantifiers like line straightness, balance of horses movements and lameness detection.</p>
      <p>Technologies used for this project were Python, Scipy, SKlearn (a python machine learning library), Javascript, Nodejs, HTML and CSS. I batch processed my raw data with a bash script and used Google App Engine and Docker to deploy.</p>
  </div>
  </body>
  <footer>
  </footer>
</html>
